{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FedorTaggenbrock/data_intensive_systems/blob/main/notebooks/main_tests_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1m1UZvaN74z",
        "outputId": "6e57c1d0-fd72-4b3c-d553-709ee7298279",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/../main_tests.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# !python ../main_tests.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcdvOolnPS8O"
      },
      "outputs": [],
      "source": [
        "# if ON_COLAB:\n",
        "#     print(\"Running in Colab: importing from GitHub.\")\n",
        "#     # wget (\"curl\") all files from github\n",
        "#     user = 'FedorTaggenbrock'\n",
        "#     repo = 'data_intensive_systems'\n",
        "#     src_dir = \"src\"\n",
        "#     pyfiles = [\"clustering.py\"]\n",
        "\n",
        "#     for pyfile in pyfiles:\n",
        "#         url = f\"https://raw.githubusercontent.com/{user}/{repo}/main/{src_dir}/{pyfile}\"\n",
        "#         !wget --no-cache --backups=1 {url}\n",
        "\n",
        "#     # Import all files\n",
        "#     try:\n",
        "#         import clustering as clustering\n",
        "#     except Exception as e:\n",
        "#         print('Error importing files on colab. Are the names right?.')\n",
        "\n",
        "# else:\n",
        "#     print(\"Running locally, importing from local.\")\n",
        "#     # Append parent folder to path\n",
        "#     sys.path.append('..')\n",
        "#     # And import all files\n",
        "#     from src import clustering as clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import requests\n",
        "# import sys\n",
        "# import time\n",
        "# import importlib\n",
        "\n",
        "# def get_file_from_github(raw_url, target_file):\n",
        "#     # Add a unique query parameter to the URL to bypass the cache\n",
        "#     raw_url += '?t=' + str(time.time())\n",
        "#     response = requests.get(raw_url)\n",
        "#     response.raise_for_status()  # Ensure we got a valid response\n",
        "#     with open(target_file, 'wb') as out_file:\n",
        "#         out_file.write(response.content)\n",
        "\n",
        "# def import_from_github(raw_urls, module_names):\n",
        "#     # Set your target path here\n",
        "#     # In Google Colab, you can use the current directory\n",
        "#     target_path = os.getcwd()\n",
        "\n",
        "#     modules = []\n",
        "#     # Download files\n",
        "#     for raw_url, module_name in zip(raw_urls, module_names):\n",
        "#         target_file = f\"{target_path}/{module_name}.py\"\n",
        "\n",
        "#         # If the module file exists, delete it first\n",
        "#         if os.path.exists(target_file):\n",
        "#             print(f'delete {target_file}')\n",
        "#             os.remove(target_file)\n",
        "\n",
        "#         get_file_from_github(raw_url, target_file)\n",
        "\n",
        "#         # If the module has been imported before, reload it\n",
        "#         if module_name in sys.modules:\n",
        "#             modules.append(importlib.reload(sys.modules[module_name]))\n",
        "#         else:\n",
        "#             # Add the directory to sys.path\n",
        "#             sys.path.insert(0, target_path)\n",
        "#             # Import your module\n",
        "#             modules.append(__import__(module_name))\n",
        "\n",
        "#     return modules\n",
        "\n",
        "\n",
        "# user = 'FedorTaggenbrock'\n",
        "# repo = 'data_intensive_systems'\n",
        "# src_dir = \"src\"\n",
        "# module_names = [\"clustering\", 'main_tests']\n",
        "# raw_urls = [f\"https://raw.githubusercontent.com/{user}/{repo}/main/{src_dir}/{modname}.py\" for modname in module_names]\n",
        "\n",
        "# clustering, main_tests = import_from_github(raw_urls, module_names)\n",
        "\n",
        "# # Now you can use your modules\n",
        "# res = clustering.jaccard_distance([1,1,0,1,0], [1,1,1,1,0])\n",
        "# print(res)\n",
        "# clustering.clustering_test1()"
      ],
      "metadata": {
        "id": "esFX-UWVv6QV",
        "outputId": "b0424979-db9d-4400-ffbe-e8ffe0aa3c05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delete /content/main_tests.py\n",
            "0.25\n",
            "update 14:40\n",
            "Initialized Spark. Start clustering.\n",
            "centroids =  [(1, 1, 1, 1, 0), (0, 0, 1, 0, 1)]\n",
            "centroids =  [(1, 1, 0, 1, 0), (0, 0, 1, 0, 1)]\n",
            "Finished clustering. Start evaluation.\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aPsU73HSlLI"
      },
      "source": [
        "**Handle importing/installing, both local and on Colab** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INJqht4-StzH",
        "outputId": "feabeba9-64df-46f4-bf3b-9d2d0535b9f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=d410fa703e5dc2a738ac8f39d3c83965a98c390f338c82939a0fdd18e4c6ef5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "ON_COLAB = 'google.colab' in sys.modules\n",
        "if ON_COLAB:\n",
        "    # Do stuff that only needs to happen on colab\n",
        "    !pip install pyspark\n",
        "else:\n",
        "    # Do stuff that only needs to happen on local computer\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "\n",
        "def import_modules():\n",
        "    if ON_COLAB:\n",
        "        print(\"Running in Colab: importing from GitHub.\")\n",
        "        # Clone the repository\n",
        "        !git clone https://github.com/FedorTaggenbrock/data_intensive_systems.git\n",
        "\n",
        "        # Change the current working directory to the cloned repository directory\n",
        "        %cd /content/data_intensive_systems\n",
        "\n",
        "        # Pull the latest changes from the repository\n",
        "        !git pull origin main\n",
        "\n",
        "        # Change back to the original working directory\n",
        "        %cd /content\n",
        "\n",
        "        # Add the path of the modules to sys.path\n",
        "        sys.path.insert(0, \"/content/data_intensive_systems/src\")\n",
        "    else:\n",
        "        print(\"Running locally, importing from local.\")\n",
        "        # Append parent folder to path\n",
        "        sys.path.append('..')\n",
        "\n",
        "    # Import and reload modules iteratively\n",
        "    module_names = ['clustering', 'evaluate_clustering', 'generate_data',\n",
        "                    'parse_data', 'main_tests']\n",
        "    for module_name in module_names:\n",
        "        module = importlib.import_module(module_name)\n",
        "        importlib.reload(module)\n",
        "        globals()[module_name] = module\n",
        "\n",
        "import_modules()\n"
      ],
      "metadata": {
        "id": "M_cMlVTtz4Ad",
        "outputId": "6573a31f-96c4-4222-de13-1979bb5c563c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Colab: importing from GitHub.\n",
            "fatal: destination path 'data_intensive_systems' already exists and is not an empty directory.\n",
            "/content/data_intensive_systems\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), 425 bytes | 425.00 KiB/s, done.\n",
            "From https://github.com/FedorTaggenbrock/data_intensive_systems\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   22e0fb0..f2365e1  main       -> origin/main\n",
            "Updating 22e0fb0..f2365e1\n",
            "Fast-forward\n",
            " .gitignore        | 1 \u001b[32m+\u001b[m\n",
            " src/clustering.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 2 insertions(+), 1 deletion(-)\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wxgQD6vN741"
      },
      "source": [
        "**Test if this works**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEkh8sL6N742",
        "outputId": "0b7357a1-3f7f-440a-f485-59d4c9e4d9f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25\n",
            "update 15:21\n",
            "Initialized Spark. Start clustering.\n",
            "centroids =  [(1, 0, 0, 1, 0), (0, 1, 1, 0, 1)]\n",
            "centroids =  [(1, 1, 0, 1, 0), (0, 0, 1, 0, 1)]\n",
            "Finished clustering. Start evaluation.\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "# print(dir(clustering))\n",
        "res = clustering.jaccard_distance([1,1,0,1,0], [1,1,1,1,0])\n",
        "print(res)\n",
        "clustering.clustering_test1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoGwAnHNN743"
      },
      "source": [
        "**Create a spark instance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN8NRmi1N743"
      },
      "outputs": [],
      "source": [
        "spark_settings = {}\n",
        "spark_instance = make_spark()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeNSBK7WN744"
      },
      "source": [
        "**Load and parse data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wg4AJxZRN744"
      },
      "outputs": [],
      "source": [
        "# Load and parse data\n",
        "data_for_spark = parse_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform clustering**"
      ],
      "metadata": {
        "id": "z7RmOlOp7Ujp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqUifQ0kN745"
      },
      "outputs": [],
      "source": [
        "# Run clustering and parameter tuning\n",
        "clustering_settings = {}\n",
        "clustering_centroid_outcomes = run_clustering(spark_instance, data_for_spark, clustering_settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06CxnhSWN745"
      },
      "outputs": [],
      "source": [
        "# Evaluate clustering results\n",
        "clustering_evaluation = evaluate_clustering(clustering_centroid_outcomes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display results**"
      ],
      "metadata": {
        "id": "WrrnSkhZ7YhR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWgrghsBN746"
      },
      "outputs": [],
      "source": [
        "# Display results (maybe only best result)\n",
        "clustering_result = display_results(clustering_evaluation"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}